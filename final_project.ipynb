{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6f814c-3cfe-4e64-a7b6-63ef03ac8df2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn, time\n",
    "import bnlearn as bn # used for creating the Baysian Network structure\n",
    "import time # for timing how long it takes to generate the synthetic data\n",
    "import random # for sampling\n",
    "import itertools # for generating combinations\n",
    "import json # for saving and loading data\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "\n",
    "def pct_error(orig, priv):\n",
    "    return np.abs(orig - priv)/orig * 100.0\n",
    "\n",
    "adult = pd.read_csv('https://github.com/jnear/cs3110-data-privacy/raw/main/homework/adult_with_pii.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eba5bad9-6690-4b50-b19f-411be912f7b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dropping some of the columns\n",
    "adult = adult.drop(['Name', 'DOB', 'SSN', 'Zip', 'fnlwgt'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29106f72-d9cd-4fdf-97bc-6cad71e5db28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inputs: a dataset in a pandas dataframe df\n",
    "#         n, an integer for number of synthetic rows\n",
    "#         epsilon, the amount of your privacy budget you want to use\n",
    "\n",
    "def create_synthetic_data(df, n, epsilon):\n",
    "    \n",
    "    # Functions used in this implementation:\n",
    "    \n",
    "    def prune_edges(dag):\n",
    "        # find a topological ordering of the dag nodes\n",
    "        topo_nodes = bn.topological_sort(dag)\n",
    "\n",
    "        # get the edges of the dag for altering\n",
    "        all_edges = dag['model_edges']\n",
    "\n",
    "        to_nodes = []\n",
    "        min_edges = []\n",
    "\n",
    "        for node in topo_nodes:\n",
    "            for edge in all_edges:\n",
    "                if edge[0] == node and (edge[1] not in to_nodes):\n",
    "                    # add edge[1] to to_nodes\n",
    "                    to_nodes.append(edge[1])\n",
    "                    # add the edge to min_edges\n",
    "                    min_edges.append(edge)\n",
    "\n",
    "        return min_edges\n",
    "    \n",
    "    \n",
    "    def dp_two_marginal(df, col1, col2, epsilon):\n",
    "    \n",
    "        # create noisy contingency table\n",
    "        ct = df[[col1, col2]].value_counts()\n",
    "        noisy_ct = ct.apply(lambda x: laplace_mech(x, 1, epsilon))\n",
    "\n",
    "        non_negative_noisy_ct = np.clip(noisy_ct, 0, None)\n",
    "        total = np.sum(np.sum(non_negative_noisy_ct))\n",
    "\n",
    "        marginals = non_negative_noisy_ct / total\n",
    "\n",
    "        return marginals.to_frame(name='probability').reset_index()\n",
    "\n",
    "    # From a list of edges, create a dictionary of marginals\n",
    "    def create_marginals(df, edges, epsilon):\n",
    "        marginal_dict = {}\n",
    "\n",
    "        epsilon_frac = len(edges)\n",
    "\n",
    "        for edge in edges:\n",
    "            marginal_dict[edge] = dp_two_marginal(df, edge[0], edge[1], epsilon_frac)\n",
    "\n",
    "        return marginal_dict\n",
    "\n",
    "    \n",
    "    def gen_samples(n, marginal):\n",
    "        samples = marginal.sample(n=n,\n",
    "                                  replace=True,\n",
    "                                  weights='probability')\n",
    "        return samples\n",
    "    \n",
    "    \n",
    "    def gen_col_val(causal_col, causal_val, target_col, marginal):\n",
    "\n",
    "            # create a new marginal based on the given value for the causal_column\n",
    "            conditional_marginal = marginal[marginal[causal_col] == causal_val]\n",
    "            total = conditional_marginal['probability'].sum()\n",
    "            conditional_marginal['probability'] / total\n",
    "\n",
    "            target_val = conditional_marginal.sample(1, replace=True, weights='probability')[target_col].iloc[0]\n",
    "\n",
    "            return target_val\n",
    "    \n",
    "    # first we create a directed acyclical graph that has\n",
    "    # estimated causal relations between the columns\n",
    "    # this uses the bnlearn library's structure_learning class\n",
    "    df_dag = bn.structure_learning.fit(df, methodtype='hc', scoretype='bic')\n",
    "    \n",
    "    # this graph might have too many edges for out needs so we will prune\n",
    "    # some of the edges to do this it helpful to sort the nodes in the DAG\n",
    "    # into a topological ordering (this is done within the function called)\n",
    "    edges = prune_edges(df_dag)\n",
    "    \n",
    "    # create the marginals\n",
    "    marginals = create_marginals(df, edges, epsilon)\n",
    "    \n",
    "    # create a new dataframe for the samples\n",
    "    synthetic_data = pd.DataFrame()\n",
    "    \n",
    "    # start at the top of the order\n",
    "    for edge in edges:\n",
    "        \n",
    "        # 1. Our dataset is currently empty\n",
    "        # Create the first 2 columns of data\n",
    "        if synthetic_data.empty:\n",
    "            synthetic_data = gen_samples(n, marginals[edge]).drop(['probability'], axis=1)\n",
    "        \n",
    "        # 2. We are creating a column that branches off an existing column\n",
    "        # create a conditional marginal using the value in edge[0]\n",
    "        # generate values for the new column using this data\n",
    "        elif edge[0] in synthetic_data.columns:\n",
    "            synthetic_data[edge[1]] = synthetic_data.apply(lambda row: \\\n",
    "                                                                     gen_col_val(edge[0], row[edge[0]], edge[1], marginals[edge]), \\\n",
    "                                                                     axis = 1)\n",
    "        \n",
    "        # 3. We are creating 2 new columns, one of which is a root, but we have already generated some columns\n",
    "        # use the two-way marginal to create 2 new columns and merge to the data\n",
    "        else:\n",
    "            # we can create the data using gen_samples and just merge it with the rest of the data\n",
    "            new_columns = gen_samples(n, marginals[edge]).drop(['probability'], axis=1)\n",
    "            # merge new columns with synthetic-data\n",
    "            synthetic_data = pd.concat([synthetic_data.reset_index(drop=True), new_columns.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    return synthetic_data, edges, df_dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d9d4b1e6-783b-4608-bbee-84cfe70a00ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bnlearn] >Warning: Computing DAG with 14 nodes can take a very long time!\n",
      "[bnlearn] >Computing best DAG using [hc]\n",
      "[bnlearn] >Set scoring type at [bic]\n",
      "[bnlearn] >Compute structure scores for model comparison (higher is better).\n",
      "210.1876049041748  seconds to create  32561  synthetic rows.\n"
     ]
    }
   ],
   "source": [
    "### This takes a few minutes to run, instead run the cell that loads the data\n",
    "\n",
    "time_start = time.time()\n",
    "adult_synth, edges, adult_dag = create_synthetic_data(adult, len(adult), 1.0)\n",
    "time_end = time.time()\n",
    "time_taken = time_end - time_start\n",
    "print(time_taken, ' seconds to create ', len(adult), ' synthetic rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "42b2afe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Save the synthetic data dataframe, edge list and DAG to file\n",
    "\n",
    "adult_synth.to_csv('adult_synth', sep=',', index=False, encoding='utf-8')\n",
    "with open(\"edges.json\", 'w') as f:\n",
    "    json.dump(edges, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e81a5897-f063-4f43-b11a-20543f326922",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Load the data here\n",
    "adult_synth = pd.read_csv('adult_synth')\n",
    "\n",
    "with open(\"edges.json\", 'r') as f:\n",
    "    edges = json.load(f)\n",
    "\n",
    "edge_ = []\n",
    "for edge in edges:\n",
    "    edge_.append((edge[0], edge[1]))\n",
    "edges = edge_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e8140c-c64e-430e-bc6b-1e5edfc3159b",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "To test the accuracy of the synthetic data I will employ several metrics:\n",
    "  - compare the counts of the synthetic data with the original data and \n",
    "  - compare 10 random set of 2-way contingencies\n",
    "  - compare 5 random set of 3-way contingencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef916b63-2358-457b-a206-8fd5969c7c96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This measures the percent error that occurs in the synthetic data as compared to the\n",
    "# original data as far as the counts in each column\n",
    "\n",
    "def compare_counts(synth_df, df):\n",
    "    avg_error_df = pd.Series()\n",
    "    for column in df.columns:\n",
    "        df_counts = df[column].value_counts() \n",
    "        synth_df_counts = synth_df[column].value_counts()\n",
    "        combined_df = df_counts.to_frame().join(other=synth_df_counts, how = 'left', sort = True, lsuffix=' original', rsuffix=' synthetic').fillna(0)\n",
    "        combined_df['Percent Error'] = pct_error(combined_df[column + ' original'], combined_df[column + ' synthetic'])\n",
    "        avg_error_df[column] = combined_df['Percent Error'].sum()/len(combined_df['Percent Error'])\n",
    "    return avg_error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef5f9c1d-c6eb-43cd-85a2-fd5f3d420c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age               11.358092\n",
       "Workclass         20.851286\n",
       "Education          3.294521\n",
       "Education-Num      3.294521\n",
       "Marital Status     4.335595\n",
       "Occupation         5.932392\n",
       "Relationship       2.814341\n",
       "Race               3.977370\n",
       "Sex                1.824359\n",
       "Capital Gain      31.318485\n",
       "Capital Loss      35.349208\n",
       "Hours per week    19.637780\n",
       "Country           12.338605\n",
       "Target             0.260381\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_counts(adult_synth, adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74c87768-a1f9-4333-ac80-bee7e38b8070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# synth_df is a dataframe of synthetic data and df the dataframe it was created from\n",
    "# columns is a list of column names\n",
    "def compare_contingency_counts(synth_df: pd.DataFrame, df: pd.DataFrame, columns: list[str]):\n",
    "    \n",
    "    df_counts = adult[columns].value_counts().rename('actual count')\n",
    "    synth_df_counts = adult_synth[columns].value_counts().rename('synthetic count')\n",
    "    combined_df = df_counts.to_frame().join(other=synth_df_counts, how = 'left', sort = True).fillna(0)\n",
    "    combined_df['Percent Error'] = pct_error(combined_df['actual count'], combined_df['synthetic count'])\n",
    "    avg_error = combined_df['Percent Error'].sum()/len(combined_df['Percent Error'])\n",
    "    \n",
    "    return avg_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ade3b36-91be-49f6-8d8f-0677f482772b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       91.000000\n",
       "mean       411.114731\n",
       "std       3255.113264\n",
       "min          3.294521\n",
       "25%         35.860593\n",
       "50%         61.666821\n",
       "75%         75.978452\n",
       "max      31107.820575\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's check how accurate we are across all possible corellations\n",
    "# As there are 14 columnns this gives us 91 possible combinations (14 choose 2)\n",
    "\n",
    "all_combinations = list(itertools.combinations(adult.columns, 2))\n",
    "\n",
    "error_two_columns = [compare_contingency_counts(adult_synth, adult, list(column_pair)) for column_pair in all_combinations]\n",
    "\n",
    "all_combinations_indices = [\"_\".join(columns) for columns in all_combinations]\n",
    "\n",
    "error_series_two = pd.Series(error_two_columns, all_combinations_indices)\n",
    "error_series_two.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4fef0ca-cdfd-4b9e-8924-679246b299dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age_Relationship                 214.263463\n",
       "Age_Target                       162.247019\n",
       "Marital Status_Relationship      921.840436\n",
       "Marital Status_Target            101.910705\n",
       "Occupation_Target                140.357746\n",
       "Relationship_Sex               31107.820575\n",
       "Relationship_Capital Gain        118.394799\n",
       "Relationship_Target              217.407822\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_series_two[error_series_two > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "234c91f8-733f-45c4-be61-ecac1698506f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age_Workclass                    80.860934\n",
       "Age_Education                    97.584902\n",
       "Age_Education-Num                97.584902\n",
       "Age_Occupation                   75.074769\n",
       "Age_Capital Gain                 75.473501\n",
       "Age_Capital Loss                 75.244264\n",
       "Age_Hours per week               87.406668\n",
       "Age_Country                      72.398276\n",
       "Workclass_Race                   63.766136\n",
       "Workclass_Capital Gain           74.862238\n",
       "Workclass_Capital Loss           70.042995\n",
       "Workclass_Hours per week         90.530002\n",
       "Workclass_Country                84.680381\n",
       "Education_Capital Gain           75.978452\n",
       "Education_Capital Loss           67.535367\n",
       "Education_Hours per week         62.604964\n",
       "Education_Country                83.930000\n",
       "Education-Num_Capital Gain       75.978452\n",
       "Education-Num_Capital Loss       67.535367\n",
       "Education-Num_Hours per week     62.604964\n",
       "Education-Num_Country            83.930000\n",
       "Marital Status_Capital Gain      74.359167\n",
       "Marital Status_Capital Loss      68.104253\n",
       "Marital Status_Hours per week    69.946226\n",
       "Marital Status_Country           65.588468\n",
       "Occupation_Capital Gain          83.672681\n",
       "Occupation_Capital Loss          84.119139\n",
       "Occupation_Hours per week        96.687703\n",
       "Occupation_Country               90.024229\n",
       "Relationship_Capital Loss        69.217296\n",
       "Relationship_Hours per week      69.830499\n",
       "Relationship_Country             61.666821\n",
       "Race_Capital Gain                58.463547\n",
       "Race_Capital Loss                52.980969\n",
       "Race_Hours per week              59.710073\n",
       "Sex_Capital Gain                 83.178183\n",
       "Sex_Capital Loss                 83.707918\n",
       "Sex_Hours per week               55.327482\n",
       "Capital Gain_Hours per week      70.291968\n",
       "Capital Gain_Country             59.037478\n",
       "Capital Loss_Hours per week      68.778427\n",
       "Capital Loss_Country             58.729015\n",
       "Hours per week_Country           72.669724\n",
       "Country_Target                   72.425713\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_series_two[error_series_two < 100][error_series_two > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2f3ac22-3667-4f84-aa12-85a21fc20459",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age_Marital Status              25.074081\n",
       "Age_Race                        43.973056\n",
       "Age_Sex                         15.151349\n",
       "Workclass_Education             45.284310\n",
       "Workclass_Education-Num         45.284310\n",
       "Workclass_Marital Status        42.330613\n",
       "Workclass_Occupation            18.486470\n",
       "Workclass_Relationship          41.399406\n",
       "Workclass_Sex                   36.472935\n",
       "Workclass_Target                24.697882\n",
       "Education_Marital Status        44.859407\n",
       "Education_Occupation            22.288185\n",
       "Education_Relationship          47.275552\n",
       "Education_Race                  49.406675\n",
       "Education_Sex                   17.663802\n",
       "Education-Num_Marital Status    44.859407\n",
       "Education-Num_Occupation        22.288185\n",
       "Education-Num_Relationship      47.275552\n",
       "Education-Num_Race              49.406675\n",
       "Education-Num_Sex               17.663802\n",
       "Marital Status_Occupation       30.779868\n",
       "Marital Status_Race             34.248054\n",
       "Occupation_Relationship         11.485707\n",
       "Occupation_Race                 38.777778\n",
       "Relationship_Race               26.240968\n",
       "Race_Sex                        18.266281\n",
       "Race_Country                    41.334069\n",
       "Race_Target                     39.624700\n",
       "Sex_Country                     33.483698\n",
       "Sex_Target                      42.614462\n",
       "Capital Gain_Capital Loss       32.892655\n",
       "Capital Gain_Target             31.026969\n",
       "Capital Loss_Target             35.248252\n",
       "Hours per week_Target           26.436209\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_series_two[error_series_two < 50][error_series_two > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8aa7003-920f-4b3f-b443-407b920fba9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education_Education-Num    3.294521\n",
       "Education_Target           7.191246\n",
       "Education-Num_Target       7.191246\n",
       "Marital Status_Sex         4.169578\n",
       "Occupation_Sex             7.625550\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_series_two[error_series_two <= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "874db665-1a0b-43fe-8949-45d65251f5b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Education-Num', 'Education'),\n",
       " ('Education', 'Occupation'),\n",
       " ('Education', 'Target'),\n",
       " ('Occupation', 'Sex'),\n",
       " ('Occupation', 'Workclass'),\n",
       " ('Occupation', 'Relationship'),\n",
       " ('Sex', 'Marital Status'),\n",
       " ('Marital Status', 'Age'),\n",
       " ('Country', 'Race'),\n",
       " ('Target', 'Capital Gain'),\n",
       " ('Target', 'Hours per week'),\n",
       " ('Target', 'Capital Loss')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "286bdf7e-9a84-408c-addb-d9339a20a949",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    12.000000\n",
       "mean     19.471737\n",
       "std      12.791880\n",
       "min       3.294521\n",
       "25%       7.516974\n",
       "50%      20.387328\n",
       "75%      27.583899\n",
       "max      41.334069\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_dag = [compare_contingency_counts(adult_synth, adult, list(column_pair)) for column_pair in edges]\n",
    "\n",
    "error_dag_indices = [\"_\".join(columns) for columns in edges]\n",
    "\n",
    "error_series_dag = pd.Series(error_dag, error_dag_indices)\n",
    "error_series_dag.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efd8f6bb-3c67-4673-ad00-c607ad73de62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education-Num_Education     3.294521\n",
       "Education_Occupation       22.288185\n",
       "Education_Target            7.191246\n",
       "Occupation_Sex              7.625550\n",
       "Occupation_Workclass       18.486470\n",
       "Occupation_Relationship    11.485707\n",
       "Sex_Marital Status          4.169578\n",
       "Marital Status_Age         25.074081\n",
       "Country_Race               41.334069\n",
       "Target_Capital Gain        31.026969\n",
       "Target_Hours per week      26.436209\n",
       "Target_Capital Loss        35.248252\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_series_dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32c24802-acda-4646-9ec4-a1a3f2006345",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      364.000000\n",
       "mean       182.549827\n",
       "std        857.791798\n",
       "min          7.191246\n",
       "25%         72.820799\n",
       "50%         80.773372\n",
       "75%         90.403688\n",
       "max      14437.413050\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the combinations of three columns:\n",
    "\n",
    "all_combinations = list(itertools.combinations(adult.columns, 3))\n",
    "\n",
    "error_three_columns = [compare_contingency_counts(adult_synth, adult, list(column_pair)) for column_pair in all_combinations]\n",
    "\n",
    "all_combinations_indices = [\"_\".join(columns) for columns in all_combinations]\n",
    "\n",
    "error_series_three = pd.Series(error_three_columns, all_combinations_indices)\n",
    "error_series_three.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b54ad61e-4e01-42e6-8b7d-5f9961396359",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age_Workclass_Relationship                      127.412900\n",
       "Age_Workclass_Target                            121.781622\n",
       "Age_Marital Status_Relationship                 233.456428\n",
       "Age_Marital Status_Target                       138.773508\n",
       "Age_Occupation_Relationship                     100.612767\n",
       "Age_Occupation_Target                           101.319829\n",
       "Age_Relationship_Race                           128.265933\n",
       "Age_Relationship_Sex                            217.802323\n",
       "Age_Relationship_Capital Gain                   110.820129\n",
       "Age_Relationship_Capital Loss                   124.298635\n",
       "Age_Relationship_Hours per week                 102.695111\n",
       "Age_Relationship_Country                        103.880784\n",
       "Age_Relationship_Target                         239.147452\n",
       "Age_Race_Target                                 122.462705\n",
       "Age_Sex_Target                                  214.120647\n",
       "Workclass_Marital Status_Relationship           644.158365\n",
       "Workclass_Marital Status_Target                 131.363502\n",
       "Workclass_Relationship_Sex                     3849.772008\n",
       "Workclass_Relationship_Target                   176.492589\n",
       "Education_Marital Status_Relationship           679.440485\n",
       "Education_Marital Status_Target                 120.514652\n",
       "Education_Relationship_Sex                      696.081029\n",
       "Education_Relationship_Target                   160.124187\n",
       "Education-Num_Marital Status_Relationship       679.440485\n",
       "Education-Num_Marital Status_Target             120.514652\n",
       "Education-Num_Relationship_Sex                  696.081029\n",
       "Education-Num_Relationship_Target               160.124187\n",
       "Marital Status_Occupation_Relationship          470.578633\n",
       "Marital Status_Occupation_Target                181.781225\n",
       "Marital Status_Relationship_Race                713.992388\n",
       "Marital Status_Relationship_Sex                2266.427377\n",
       "Marital Status_Relationship_Capital Gain        150.773802\n",
       "Marital Status_Relationship_Capital Loss        169.897628\n",
       "Marital Status_Relationship_Hours per week      185.671549\n",
       "Marital Status_Relationship_Country             159.911378\n",
       "Marital Status_Relationship_Target             1074.277790\n",
       "Marital Status_Race_Target                      147.515383\n",
       "Marital Status_Sex_Target                       123.365294\n",
       "Marital Status_Hours per week_Target            103.226390\n",
       "Marital Status_Country_Target                   104.824046\n",
       "Occupation_Relationship_Sex                     626.083925\n",
       "Occupation_Relationship_Target                  357.484772\n",
       "Occupation_Sex_Target                           121.661286\n",
       "Relationship_Race_Sex                          6188.697611\n",
       "Relationship_Race_Target                        249.385337\n",
       "Relationship_Sex_Capital Gain                  1067.847101\n",
       "Relationship_Sex_Capital Loss                  1550.801561\n",
       "Relationship_Sex_Hours per week                 413.520191\n",
       "Relationship_Sex_Country                       1193.970036\n",
       "Relationship_Sex_Target                       14437.413050\n",
       "Relationship_Capital Gain_Target                116.706768\n",
       "Relationship_Hours per week_Target              117.201962\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_series_three[error_series_three > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f1c1bb-a353-464c-b1ca-ed905844ed17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
